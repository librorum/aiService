import Debug from 'debug'
const debug = Debug('ai_service:ai_service')
import 'dotenv/config'
import fs from 'fs/promises'
import path from 'path'
import OpenAiService from './provider_services/openai_service.js'
import AnthropicService from './provider_services/anthropic_service.js'
import GeminiService from './provider_services/gemini_service.js'
import StabilityService from './provider_services/stability_service.js'
import RunwayService from './provider_services/runway_service.js'
import ElevenLabsService from './provider_services/elevenlabs_service.js'


let ai_models = []

// 1M ë‹¨ìœ„ë¡œ ì €ìž¥ëœ ê°€ê²©ì„ 1í† í° ë‹¨ìœ„ë¡œ ë³€í™˜
/*
UPDATE AIModels
SET
  input_token_price = input_token_price_1M / 1000000,
  output_token_price = output_token_price_1M / 1000000;
*/


class AIService {
  constructor() {
    // this.factory = aiServiceFactory

    // ì„œë¹„ìŠ¤ ì‹œìž‘ì‹œì— API í‚¤ ìœ íš¨ì„± ì²´í¬
    this.checkApiKey()

    this.tools = {}
    this.functions = {}
    this.provider_services = {}
    this.provider_services['openai'] = new OpenAiService(this)
    this.provider_services['anthropic'] = new AnthropicService(this)
    this.provider_services['gemini'] = new GeminiService(this)
    this.provider_services['stability'] = new StabilityService(this)
    this.provider_services['runway'] = new RunwayService(this)
    this.provider_services['elevenlabs'] = new ElevenLabsService(this)

  }

  /**
   * API í‚¤ ì„¤ì • ìƒíƒœ í™•ì¸ (ì„œë¹„ìŠ¤ ì‹œìž‘ì‹œ ìžë™ í˜¸ì¶œë¨)
   * ì½˜ì†”ì— API í‚¤ ì„¤ì • ìƒíƒœë¥¼ ì¶œë ¥í•˜ì—¬ ê°œë°œìžê°€ í™•ì¸í•  ìˆ˜ ìžˆê²Œ í•¨
   */
  checkApiKey() {
    debug('===== AI ì„œë¹„ìŠ¤ API í‚¤ ì„¤ì • ìƒíƒœ í™•ì¸ =====')

    debug('OPENAI_API_KEY', process.env.OPENAI_API_KEY)
    debug('ANTHROPIC_API_KEY', process.env.ANTHROPIC_API_KEY)
    debug('GEMINI_API_KEY', process.env.GEMINI_API_KEY)
    debug('STABILITY_API_KEY', process.env.STABILITY_API_KEY)
    debug('RUNWAY_API_KEY', process.env.RUNWAY_API_KEY)
    debug('ELEVENLABS_API_KEY', process.env.ELEVENLABS_API_KEY)
    debug('TOPVIEW_API_KEY', process.env.TOPVIEW_API_KEY)

    const api_keys = {
      'OpenAI API': process.env.OPENAI_API_KEY,
      'Anthropic API': process.env.ANTHROPIC_API_KEY,
      'Google Gemini API': process.env.GEMINI_API_KEY,
      'Stability AI API': process.env.STABILITY_API_KEY,
      'Runway API': process.env.RUNWAY_API_KEY,
      'ElevenLabs API': process.env.ELEVENLABS_API_KEY,
      'TopView API': process.env.TOPVIEW_API_KEY
    }

    let all_keys_valid = true

    for (const [service_name, api_key] of Object.entries(api_keys)) {
      const status = api_key ? 'âœ… ì„¤ì •ë¨' : 'âŒ ì„¤ì •ë˜ì§€ ì•ŠìŒ'
      debug(`${service_name}: ${status}`)

      if (!api_key) all_keys_valid = false
    }

    if (!all_keys_valid) {
      debug('ì¼ë¶€ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.')
    } else {
      debug('ëª¨ë“  API í‚¤ê°€ ì •ìƒì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.')
    }

    debug('=========================================')
  }

  /**
   * API í‚¤ ìœ íš¨ì„± ê°„ë‹¨ í…ŒìŠ¤íŠ¸
   * ê° ì„œë¹„ìŠ¤ì— ëŒ€í•´ API í‚¤ê°€ ë¹„ì–´ìžˆì§€ ì•Šì€ì§€ í™•ì¸í•˜ê³  ê²°ê³¼ ë°˜í™˜
   * @returns {Object} API í‚¤ ì„¤ì • ìƒíƒœ ê°ì²´
   */
  testApiKeys() {
    const results = {
      openai: {
        provider: 'openAI',
        key_configured: !!process.env.OPENAI_API_KEY,
      },
      anthropic: {
        provider: 'anthropic',
        key_configured: !!process.env.ANTHROPIC_API_KEY,
      },
      gemini: {
        provider: 'gemini',
        key_configured: !!process.env.GEMINI_API_KEY,
      },
      stability: {
        provider: 'stability',
        key_configured: !!process.env.STABILITY_API_KEY,
      },
      runway: {
        provider: 'runway',
        key_configured: !!process.env.RUNWAY_API_KEY,
      },
      elevenlabs: {
        provider: 'elevenlabs',
        key_configured: !!process.env.ELEVENLABS_API_KEY,
      }
    }

    debug('===== API í‚¤ ì„¤ì • ìƒíƒœ í…ŒìŠ¤íŠ¸ =====')
    debug('ðŸ‡°ðŸ‡· API í‚¤ ì„¤ì • ìƒíƒœë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.')

    for (const [provider_id, status] of Object.entries(results)) {
      const status_icon = status.key_configured ? 'âœ…' : 'âŒ'
      const status_text = status.key_configured ? 'ì„¤ì •ë¨' : 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'

      debug(`${status_icon} ${status.provider}: ${status_text} `)
      // const supported_features = Object.entries(status.supports)
      //   .filter(([feature, supported]) => supported)
      //   .map(([feature]) => feature)
      // debug(`   ì§€ì› ê¸°ëŠ¥: ${supported_features.join(', ')} `)
    }

    return results
  }

  /**
   * í…ìŠ¤íŠ¸ ìƒì„±ì„ ì§€ì›í•˜ëŠ” ëª¨ë“  ëª¨ë¸ ì •ë³´ë¥¼ ë°˜í™˜
   * @returns {Array} ëª¨ë¸ëª…ê³¼ í”„ë¡œë°”ì´ë” ì •ë³´ë¥¼ í¬í•¨í•œ ê°ì²´ ë°°ì—´
   */
  getModels() {
    const text_models = []

    // ê° í”„ë¡œë°”ì´ë”ì—ì„œ í…ìŠ¤íŠ¸ ì§€ì› ëª¨ë¸ ìˆ˜ì§‘
    for (const [provider_name, provider_service] of Object.entries(this.provider_services)) {
      if (provider_service.models_info) {
        const provider_text_models = provider_service.models_info
          .filter(model_info => model_info.support_text_output === true)
          .map(model_info => ({
            model: model_info.model,
            provider: provider_name
          }))

        text_models.push(...provider_text_models)
      }
    }

    return text_models
  }

  getProviderByModel(model) {
    for (const [provider_name, provider_service] of Object.entries(this.provider_services)) {
      if (provider_service.models_info) {
        const provider_model_info = provider_service.models_info.find(model_info => model_info.model === model)
        if (provider_model_info) {
          return provider_name
        }
      }
    }
    return null
  }

  registerTool({ name, description, parameters, func }) {
    this.tools[name] = {
      name,
      description,
      parameters,
    }
    this.functions[name] = func
  }

  async generateText({
    provider = null,
    model,
    prompt,
    ai_rule,
    temperature = 0.7,
    max_tokens = 2000,
    web_search = false,
    conversation_history = null, // ê¸°ì¡´ ë°©ì‹ (ëª¨ë“  provider ì§€ì›)
    use_conversation_state = false, // OpenAI Responses API ì‚¬ìš© ì—¬ë¶€
    store = true, // OpenAI Responses APIì—ì„œ ëŒ€í™” ì €ìž¥ ì—¬ë¶€
    previous_response_id = null, // OpenAI Responses APIìš© ì´ì „ ì‘ë‹µ ID
  }) {
    if (!provider && model) {
      provider = this.getProviderByModel(model)
    }
    provider = provider || 'openai'
    const ai_provider = this.provider_services[provider]

    const start_time = new Date()
    const result = await ai_provider.generateText({
      prompt,
      model,
      temperature,
      max_tokens,
      ai_rule,
      web_search,
      conversation_history,
      use_conversation_state, // OpenAI ì „ìš©
      store, // OpenAI ì „ìš©
      previous_response_id // OpenAI ì „ìš©
    })

    const end_time = new Date()
    const execution_time = (end_time - start_time) / 1000 // ì´ˆ ë‹¨ìœ„
    debug(`ì²˜ë¦¬ ì‹œê°„: ${execution_time}ì´ˆ`)

    return {
      ...result,
      execution_time,
      conversation_history: result.updated_conversation_history || conversation_history,
      response_id: result.response_id // OpenAI Responses APIì˜ ì‘ë‹µ ID (ìžˆëŠ” ê²½ìš°)
    }
  }

  async generateImage({
    provider = 'openai',
    model,
    prompt,
    width = 1024,
    height = 1024,
    n = 1,
  }) {
    const ai_provider = this.provider_services[provider]

    const start_time = new Date()
    const {
      image,
      image_type, // base64, url, buffer
      input_tokens,
      output_tokens,
      total_tokens,
      error,
      model_used,
      cost
    } = await ai_provider.generateImage({
      model,
      prompt,
      width,
      height,
      n,
    })

    const end_time = new Date()
    const execution_time = (end_time - start_time) / 1000 // ì´ˆ ë‹¨ìœ„
    debug(`ì²˜ë¦¬ ì‹œê°„: ${execution_time}ì´ˆ`)

    return {
      image,
      image_type,
      input_tokens,
      output_tokens,
      total_tokens,
      error,
      model: model_used,
      cost,
      execution_time
    }
  }

  async generateTTS({
    provider = 'openai',
    model,
    prompt,
    voice,
    voice_id,
    response_format = 'mp3',
    ai_rule = 'Speak in a friendly and engaging tone',
  }) {
    const ai_provider = this.provider_services[provider]
    const start_time = new Date()
    const { audio, error, model_used, usage, cost } = await ai_provider.generateTTS({
      model,
      prompt,
      voice,
      voice_id,
      response_format,
      ai_rule,
    })
    const end_time = new Date()
    const execution_time = (end_time - start_time) / 1000 // ì´ˆ ë‹¨ìœ„
    debug(`ì²˜ë¦¬ ì‹œê°„: ${execution_time}ì´ˆ`)

    return {
      model: model_used,
      audio,
      error,
      usage,
      cost,
      execution_time
    }
  }

  async generateVideo({
    provider = 'runway',
    model,
    input,
    ...options
  }) {
    const ai_provider = this.provider_services[model]

    const start_time = new Date()
    const result = await ai_provider.generateVideo(input, {
      model,
      ...options
    })

    const end_time = new Date()
    const execution_time = (end_time - start_time) / 1000 // ì´ˆ ë‹¨ìœ„
    debug(`ì²˜ë¦¬ ì‹œê°„: ${execution_time}ì´ˆ`)


    return {
      data: result.data || result,
      execution_time
    }
  }

  /**
   * í•˜ë‚˜ ë˜ëŠ” ëª¨ë“  AI í”„ë¡œë°”ì´ë” í…ŒìŠ¤íŠ¸
   * @param {string} [providerName] - í…ŒìŠ¤íŠ¸í•  í”„ë¡œë°”ì´ë” ì´ë¦„ (ì„ íƒì‚¬í•­). ì œê³µí•˜ì§€ ì•Šìœ¼ë©´ ëª¨ë“  í”„ë¡œë°”ì´ë”ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
   * @param {string} [feature] - í…ŒìŠ¤íŠ¸í•  ê¸°ëŠ¥ ('text', 'image', 'audio', 'video', 'conversation', 'conversation_state'). nullì¸ ê²½ìš° ëª¨ë“  ì§€ì› ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸.
   * @param {Array} [system_tools] - ì‚¬ìš©í•  ì‹œìŠ¤í…œ ë„êµ¬ ë°°ì—´ (ì˜ˆ: ['web_search'])
   * @param {Array} [user_tools] - ì‚¬ìš©ìž ë„êµ¬ ë°°ì—´ (ì˜ˆ: ['web_search'])
   */
  async test(providerName, feature = null, system_tools = [], user_tools = []) {
    if (providerName) {
      // íŠ¹ì • í”„ë¡œë°”ì´ë” í…ŒìŠ¤íŠ¸
      const provider_service = this.provider_services[providerName.toLowerCase()]
      if (!provider_service) {
        const message = `Provider '${providerName}' not found.Available providers: ${Object.keys(this.provider_services).join(', ')}`
        debug(message)
        return { error: message }
      }
      if (user_tools.includes('calculator')) {
        this.registerTool({
          name: 'calculator',
          description: 'Evaluates a mathematical expression.',
          parameters: {
            type: 'object',
            properties: {
              expression: {
                type: 'string',
                description: 'The mathematical expression to evaluate, e.g., "1+2*3"',
              },
            },
            required: ['expression'],
            additionalProperties: false,
          },
          func: ({ expression }) => {
            try {
              // ìž…ë ¥ëœ ìˆ˜ì‹ì„ ì•ˆì „í•˜ê²Œ í‰ê°€í•©ë‹ˆë‹¤.
              if (!/^[0-9+\-*/().\s]+$/.test(expression)) {
                throw new Error("Invalid expression")
              }
              const result = Function(`"use strict"; return (${expression})`)()
              return result
            } catch (error) {
              return "Invalid expression"
            }
          }
        })
      }
      debug(`\n${providerName} test begin(feature: ${feature || 'all'}, system_tools: ${system_tools}, user_tools: ${user_tools})`)
      
      // conversation ê´€ë ¨ í…ŒìŠ¤íŠ¸ëŠ” ë³„ë„ ì²˜ë¦¬
      if (feature === 'conversation') {
        await this.testConversation(providerName)
      } else if (feature === 'conversation_state') {
        if (providerName.toLowerCase() === 'openai') {
          await this.testConversationState()
        } else {
          debug(`Conversation StateëŠ” OpenAIì—ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤. ${providerName}ì—ì„œëŠ” ê¸°ì¡´ conversation í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.`)
          await this.testConversation(providerName)
        }
      } else {
        await provider_service.test({ feature, system_tools, user_tools })
      }
      
      debug(`${providerName} test completed`)
      return { status: 'completed', provider: providerName, feature, system_tools, user_tools }
    } else {
      // ëª¨ë“  í”„ë¡œë°”ì´ë” í…ŒìŠ¤íŠ¸
      const results = {}
      for (const [name, provider_service] of Object.entries(this.provider_services)) {
        debug(`\n${name} test begin(feature: ${feature || 'all'}, system_tools: ${system_tools}, user_tools: ${user_tools})`)
        
        // conversation ê´€ë ¨ í…ŒìŠ¤íŠ¸ëŠ” ë³„ë„ ì²˜ë¦¬
        if (feature === 'conversation') {
          await this.testConversation(name)
        } else if (feature === 'conversation_state') {
          if (name.toLowerCase() === 'openai') {
            await this.testConversationState()
          } else {
            debug(`Conversation StateëŠ” OpenAIì—ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤. ${name}ì—ì„œëŠ” ê¸°ì¡´ conversation í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.`)
            await this.testConversation(name)
          }
        } else {
          await provider_service.test({ feature, system_tools, user_tools })
        }
        
        debug(`${name} test completed`)
        results[name] = { status: 'completed', feature, system_tools, user_tools }
      }
      return { status: 'completed', results }
    }
  }

  // ëŒ€í™” ížˆìŠ¤í† ë¦¬ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ (ê¸°ì¡´ ë°©ì‹)
  async testConversation(provider = 'openai') {
    console.log(`\n=== ${provider.toUpperCase()} ëŒ€í™” ížˆìŠ¤í† ë¦¬ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ ë°©ì‹) ===`)
    
    let conversation_history = null
    
    // ì²« ë²ˆì§¸ ëŒ€í™”
    console.log('\n1. ì²« ë²ˆì§¸ ì§ˆë¬¸: "ë‚´ ì´ë¦„ì„ ê¹€ì² ìˆ˜ë¼ê³  ê¸°ì–µí•´ì¤˜"')
    const response1 = await this.generateText({
      provider,
      prompt: 'ë‚´ ì´ë¦„ì„ ê¹€ì² ìˆ˜ë¼ê³  ê¸°ì–µí•´ì¤˜',
      conversation_history
    })
    console.log('ì‘ë‹µ:', response1.text)
    conversation_history = response1.conversation_history
    
    // ë‘ ë²ˆì§¸ ëŒ€í™”
    console.log('\n2. ë‘ ë²ˆì§¸ ì§ˆë¬¸: "ë‚´ ì´ë¦„ì´ ë­ì•¼?"')
    const response2 = await this.generateText({
      provider,
      prompt: 'ë‚´ ì´ë¦„ì´ ë­ì•¼?',
      conversation_history
    })
    console.log('ì‘ë‹µ:', response2.text)
    conversation_history = response2.conversation_history
    
    // ì„¸ ë²ˆì§¸ ëŒ€í™”
    console.log('\n3. ì„¸ ë²ˆì§¸ ì§ˆë¬¸: "ë‚´ ì´ë¦„ì„ ì˜ì–´ë¡œ ì¨ì¤˜"')
    const response3 = await this.generateText({
      provider,
      prompt: 'ë‚´ ì´ë¦„ì„ ì˜ì–´ë¡œ ì¨ì¤˜',
      conversation_history
    })
    console.log('ì‘ë‹µ:', response3.text)
    conversation_history = response3.conversation_history
    
    // ë„¤ ë²ˆì§¸ ëŒ€í™”
    console.log('\n4. ë„¤ ë²ˆì§¸ ì§ˆë¬¸: "ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ê°€ ë‚˜ëˆˆ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì¤˜"')
    const response4 = await this.generateText({
      provider,
      prompt: 'ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ê°€ ë‚˜ëˆˆ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì¤˜',
      conversation_history
    })
    console.log('ì‘ë‹µ:', response4.text)
    
    console.log('\n=== ëŒ€í™” ížˆìŠ¤í† ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===')
  }

  // OpenAI Conversation State í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ (ìƒˆë¡œìš´ ë°©ì‹)
  async testConversationState() {
    console.log('\n=== OpenAI Conversation State í…ŒìŠ¤íŠ¸ (ìƒˆë¡œìš´ ë°©ì‹) ===')
    
    let previous_response_id = null
    
    // ì²« ë²ˆì§¸ ëŒ€í™”
    console.log('\n1. ì²« ë²ˆì§¸ ì§ˆë¬¸: "ë‚´ ì´ë¦„ì„ ê¹€ì² ìˆ˜ë¼ê³  ê¸°ì–µí•´ì¤˜"')
    const response1 = await this.generateText({
      provider: 'openai',
      prompt: 'ë‚´ ì´ë¦„ì„ ê¹€ì² ìˆ˜ë¼ê³  ê¸°ì–µí•´ì¤˜',
      use_conversation_state: true,
      store: true
    })
    console.log('ì‘ë‹µ:', response1.text)
    console.log('ì‘ë‹µ ID:', response1.response_id)
    previous_response_id = response1.response_id
    
    // ë‘ ë²ˆì§¸ ëŒ€í™”
    console.log('\n2. ë‘ ë²ˆì§¸ ì§ˆë¬¸: "ë‚´ ì´ë¦„ì´ ë­ì•¼?"')
    const response2 = await this.generateText({
      provider: 'openai',
      prompt: 'ë‚´ ì´ë¦„ì´ ë­ì•¼?',
      use_conversation_state: true,
      store: true,
      previous_response_id
    })
    console.log('ì‘ë‹µ:', response2.text)
    console.log('ì‘ë‹µ ID:', response2.response_id)
    previous_response_id = response2.response_id
    
    // ì„¸ ë²ˆì§¸ ëŒ€í™”
    console.log('\n3. ì„¸ ë²ˆì§¸ ì§ˆë¬¸: "ë‚´ ì´ë¦„ì„ ì˜ì–´ë¡œ ì¨ì¤˜"')
    const response3 = await this.generateText({
      provider: 'openai',
      prompt: 'ë‚´ ì´ë¦„ì„ ì˜ì–´ë¡œ ì¨ì¤˜',
      use_conversation_state: true,
      store: true,
      previous_response_id
    })
    console.log('ì‘ë‹µ:', response3.text)
    console.log('ì‘ë‹µ ID:', response3.response_id)
    previous_response_id = response3.response_id
    
    // ë„¤ ë²ˆì§¸ ëŒ€í™”
    console.log('\n4. ë„¤ ë²ˆì§¸ ì§ˆë¬¸: "ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ê°€ ë‚˜ëˆˆ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì¤˜"')
    const response4 = await this.generateText({
      provider: 'openai',
      prompt: 'ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ê°€ ë‚˜ëˆˆ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì¤˜',
      use_conversation_state: true,
      store: true,
      previous_response_id
    })
    console.log('ì‘ë‹µ:', response4.text)
    console.log('ì‘ë‹µ ID:', response4.response_id)
    
    console.log('\n=== Conversation State í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===')
    console.log('ìž¥ì : ë§¤ë²ˆ ì „ì²´ ëŒ€í™” ížˆìŠ¤í† ë¦¬ë¥¼ ì „ì†¡í•˜ì§€ ì•Šì•„ í† í° íš¨ìœ¨ì !')
  }
}

const aiService = new AIService()

console.log(aiService.getModels())

export default aiService

// ë©”ì¸ ì‹¤í–‰ë¶€
// ðŸ‡°ðŸ‡· ë©”ì¸ ì‹¤í–‰ë¶€ìž…ë‹ˆë‹¤.
debug('import.meta.url', import.meta.url)
if (import.meta.url === `file://${process.argv[1]}`) {
  debug('ë©”ì¸ ì‹¤í–‰ë¶€')

  // ëª…ë ¹ì¤„ ì¸ìˆ˜ ì²˜ë¦¬
  const args = process.argv.slice(2)
  const firstArg = args[0]?.toLowerCase()
  const secondArg = args[1]?.toLowerCase()

  // ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œë°”ì´ë” ëª©ë¡
  const availableProviders = Object.keys(aiService.provider_services).join(', ')

  // ë„ì›€ë§ ì¶œë ¥ í•¨ìˆ˜
  const showHelp = () => {
    console.log('\nì‚¬ìš©ë²•:')
    console.log('  node index.js <ëª…ë ¹ì–´> [ì˜µì…˜]')
    console.log('')
    console.log('ëª…ë ¹ì–´:')
    console.log('  text [provider]           - í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸')
    console.log('  image [provider]          - ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸')
    console.log('  tts [provider]            - ìŒì„± í•©ì„± í…ŒìŠ¤íŠ¸')
    console.log('  stt [provider]            - ìŒì„± ì¸ì‹ í…ŒìŠ¤íŠ¸')
    console.log('  video [provider]          - ë¹„ë””ì˜¤ ìƒì„± í…ŒìŠ¤íŠ¸')
    console.log('  websearch [provider]      - ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸')
    console.log('  conversation [provider]   - ëŒ€í™” ížˆìŠ¤í† ë¦¬ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ ë°©ì‹)')
    console.log('  conversation_state        - OpenAI Conversation State í…ŒìŠ¤íŠ¸ (ìƒˆë¡œìš´ ë°©ì‹)')
    console.log('')
    console.log('Provider ì˜µì…˜: openai, anthropic, gemini')
    console.log('')
    console.log('ì˜ˆì‹œ:')
    console.log('  node index.js text openai')
    console.log('  node index.js conversation anthropic')
    console.log('  node index.js conversation_state')
    console.log('  node index.js websearch gemini')
    console.log('')
    console.log('í†µí•© í…ŒìŠ¤íŠ¸ (aiService.test() ì‚¬ìš©):')
    console.log('  node index.js openai                 - OpenAI ëª¨ë“  ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸')
    console.log('  node index.js                        - ëª¨ë“  provider ëª¨ë“  ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸')
    process.exit(0)
  }

  // ì¸ìˆ˜ê°€ ì—†ìœ¼ë©´ ë„ì›€ë§ í‘œì‹œ
  if (args.length === 0) {
    showHelp()
  }

  // ì²« ë²ˆì§¸ ì¸ìžê°€ í”„ë¡œë°”ì´ë” ì´ë¦„ì¸ì§€ í™•ì¸
  if (firstArg && !['text', 'image', 'tts', 'video', 'stt', 'websearch', 'tool', 'image_generator', 'conversation', 'conversation_state'].includes(firstArg)) {
    // í”„ë¡œë°”ì´ë” ì§€ì • í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    debug(`${firstArg} í”„ë¡œë°”ì´ë” í…ŒìŠ¤íŠ¸ ì‹¤í–‰`)
    aiService.test(firstArg).then(() => {
      debug(`${firstArg} í”„ë¡œë°”ì´ë” í…ŒìŠ¤íŠ¸ ì™„ë£Œ`)
    })
  } else {
    // ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ìœ í˜•ì— ë”°ë¥¸ ì‹¤í–‰
    const testType = firstArg
    const provider = secondArg // ë‘ ë²ˆì§¸ ì¸ìžë¡œ í”„ë¡œë°”ì´ë” ì§€ì • ê°€ëŠ¥

    const testRunner = async (feature = null, system_tools = [], user_tools = []) => {
      if (provider) {
        // íŠ¹ì • í”„ë¡œë°”ì´ë”ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        debug(`${provider} í”„ë¡œë°”ì´ë”ì˜ ${testType || 'ê¸°ë³¸'} í…ŒìŠ¤íŠ¸ ì‹¤í–‰`)
        await aiService.test(provider, feature, system_tools, user_tools)
      } else {
        // ì „ì²´ í”„ë¡œë°”ì´ë” í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        debug(`${testType || 'ê¸°ë³¸'} í…ŒìŠ¤íŠ¸ ì‹¤í–‰`)
        await aiService.test(null, feature, system_tools, user_tools)
      }
    }

    const testConversation = async (providerName = 'openai') => {
      debug('=== ëŒ€í™” ížˆìŠ¤í† ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œìž‘ ===')
      
      let conversation_history = null
      
      // ì²« ë²ˆì§¸ ëŒ€í™”
      debug('ì²« ë²ˆì§¸ ì§ˆë¬¸: ë‚´ ì´ë¦„ì„ ê¹€ì² ìˆ˜ë¼ê³  ê¸°ì–µí•´ì¤˜')
      const response1 = await aiService.generateText({
        provider: providerName,
        prompt: 'ë‚´ ì´ë¦„ì„ ê¹€ì² ìˆ˜ë¼ê³  ê¸°ì–µí•´ì¤˜',
        conversation_history
      })
      debug('ì²« ë²ˆì§¸ ì‘ë‹µ:', response1.text)
      conversation_history = response1.conversation_history
      
      // ë‘ ë²ˆì§¸ ëŒ€í™” (ì´ì „ ëŒ€í™” ê¸°ì–µí•˜ëŠ”ì§€ í™•ì¸)
      debug('ë‘ ë²ˆì§¸ ì§ˆë¬¸: ë‚´ ì´ë¦„ì´ ë­ì•¼?')
      const response2 = await aiService.generateText({
        provider: providerName,
        prompt: 'ë‚´ ì´ë¦„ì´ ë­ì•¼?',
        conversation_history
      })
      debug('ë‘ ë²ˆì§¸ ì‘ë‹µ:', response2.text)
      conversation_history = response2.conversation_history
      
      // ì„¸ ë²ˆì§¸ ëŒ€í™” (ë” ë³µìž¡í•œ ì»¨í…ìŠ¤íŠ¸)
      debug('ì„¸ ë²ˆì§¸ ì§ˆë¬¸: ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ìƒ‰ê¹”ì€ íŒŒëž€ìƒ‰ì´ì•¼')
      const response3 = await aiService.generateText({
        provider: providerName,
        prompt: 'ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ìƒ‰ê¹”ì€ íŒŒëž€ìƒ‰ì´ì•¼',
        conversation_history
      })
      debug('ì„¸ ë²ˆì§¸ ì‘ë‹µ:', response3.text)
      conversation_history = response3.conversation_history
      
      // ë„¤ ë²ˆì§¸ ëŒ€í™” (ì´ì „ ëª¨ë“  ì •ë³´ ê¸°ì–µí•˜ëŠ”ì§€ í™•ì¸)
      debug('ë„¤ ë²ˆì§¸ ì§ˆë¬¸: ë‚´ ì´ë¦„ê³¼ ì¢‹ì•„í•˜ëŠ” ìƒ‰ê¹”ì„ ë§í•´ì¤˜')
      const response4 = await aiService.generateText({
        provider: providerName,
        prompt: 'ë‚´ ì´ë¦„ê³¼ ì¢‹ì•„í•˜ëŠ” ìƒ‰ê¹”ì„ ë§í•´ì¤˜',
        conversation_history
      })
      debug('ë„¤ ë²ˆì§¸ ì‘ë‹µ:', response4.text)
      
      debug('=== ëŒ€í™” ížˆìŠ¤í† ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===')
      debug('ìµœì¢… ëŒ€í™” ížˆìŠ¤í† ë¦¬:', JSON.stringify(response4.conversation_history, null, 2))
    }

    switch (testType) {
      case 'text':
        debug('í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
        testRunner('text').then(() => debug('í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ'))
        break
      case 'websearch':
        debug('ì›¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
        testRunner('text', ['web_search'], []).then(() => debug('ì›¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ'))
        break
      case 'tool':
        debug('tool í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
        testRunner('text', [], ['calculator']).then(() => debug('tool í…ŒìŠ¤íŠ¸ ì™„ë£Œ'))
        break
      case 'image_generator':
        debug('ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
        testRunner('text', [], ['image_generator']).then(() => debug('ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ'))
        break
      case 'image':
        debug('ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
        testRunner('image').then(() => debug('ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ'))
        break
      case 'tts':
        debug('TTS í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
        testRunner('audio').then(() => debug('TTS í…ŒìŠ¤íŠ¸ ì™„ë£Œ'))
        break
      case 'video':
        debug('ë¹„ë””ì˜¤ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
        testRunner('video').then(() => debug('ë¹„ë””ì˜¤ ìƒì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ'))
        break
      case 'stt':
        debug('STT í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
        testRunner('audio').then(() => debug('STT í…ŒìŠ¤íŠ¸ ì™„ë£Œ'))
        break
      case 'conversation':
        debug('ëŒ€í™” ížˆìŠ¤í† ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
        testConversation(provider).then(() => debug('ëŒ€í™” ížˆìŠ¤í† ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ'))
        break
      case 'conversation_state':
        debug('OpenAI Conversation State í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
        aiService.testConversationState().then(() => debug('OpenAI Conversation State í…ŒìŠ¤íŠ¸ ì™„ë£Œ'))
        break
      default:
        if (testType) {
          debug(`ì•Œ ìˆ˜ ì—†ëŠ” í…ŒìŠ¤íŠ¸ ìœ í˜•: ${testType}. ì‚¬ìš© ê°€ëŠ¥í•œ í…ŒìŠ¤íŠ¸ ìœ í˜•: text, image, tts, video, stt, websearch`)
          debug(`ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œë°”ì´ë”: ${availableProviders}`)
        }
        debug('ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
        testRunner().then(() => debug('ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ'))
    }
  }
}
